{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generative AI has numerous business applications across various industries, including:\n",
       "\n",
       "1. **Content Generation**: Automate content creation, such as writing articles, blog posts, social media posts, and product descriptions, to increase efficiency and reduce costs.\n",
       "2. **Image and Video Creation**: Generate high-quality images and videos for marketing materials, product demonstrations, and advertising campaigns.\n",
       "3. **Product Design and Development**: Use AI to design and develop new products, such as 3D models, prototypes, and product mockups, reducing the need for manual drafting and prototyping.\n",
       "4. **Customer Service Chatbots**: Develop chatbots that use generative AI to provide personalized customer support, answering frequently asked questions and resolving simple issues.\n",
       "5. **Predictive Analytics and Forecasting**: Leverage generative AI to analyze large datasets and predict future trends, enabling businesses to make informed decisions and anticipate market shifts.\n",
       "6. **Language Translation**: Use generative AI-powered translation tools to automate language translation, improving communication with global customers and partners.\n",
       "7. **Creative Writing and Copywriting**: Collaborate with humans or use generative AI alone to generate high-quality creative writing, such as scripts, poetry, and advertising copy.\n",
       "8. **Music and Audio Generation**: Create custom music tracks, voiceovers, and audio effects for marketing campaigns, product demos, and video content.\n",
       "9. **Market Research and Insights**: Use generative AI to analyze customer feedback, social media conversations, and market trends, providing businesses with valuable insights and recommendations.\n",
       "10. **Automated Customer Segmentation**: Segment customers based on their behavior, preferences, and demographics using generative AI algorithms, enabling targeted marketing campaigns and improved customer experience.\n",
       "\n",
       "Some specific business applications of Generative AI include:\n",
       "\n",
       "* **Salesforce**: Uses generative AI to personalize sales interactions, recommend products, and analyze customer data.\n",
       "* **Dyson**: Employs generative AI to design new product prototypes and improve existing ones.\n",
       "* **Accenture**: Develops custom chatbots using generative AI to provide exceptional customer service experiences.\n",
       "* **Nike**: Utilizes generative AI to create personalized shoe designs and optimize product development.\n",
       "\n",
       "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "Markdown(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generative AI has numerous business applications across various industries. Here are some examples:\n",
       "\n",
       "1. **Content Generation**: Generative AI can be used to create high-quality content, such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources while maintaining consistency in their brand's voice and tone.\n",
       "2. **Marketing Automation**: Generative AI can automate marketing tasks, such as email templates, ad copywriting, and social media posting. This can help businesses personalize their marketing efforts and improve engagement with their target audience.\n",
       "3. **Product Design and Development**: Generative AI can be used to design new products, such as clothing, furniture, or electronics. It can also assist in the development process by generating prototypes, suggestions for material combinations, and more.\n",
       "4. **Customer Service Chatbots**: Generative AI-powered chatbots can help businesses provide 24/7 customer support, answering frequently asked questions, resolving issues, and routing complex inquiries to human representatives.\n",
       "5. **Data Analysis and Visualization**: Generative AI can be used to analyze large datasets and generate insights, such as identifying trends, patterns, and correlations. It can also create interactive visualizations to help businesses communicate their findings more effectively.\n",
       "6. **Recommendation Systems**: Generative AI can help businesses build personalized recommendation systems for customers. This can include product suggestions based on browsing history, purchase behavior, or search queries.\n",
       "7. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations, such as predicting demand, identifying bottlenecks, and recommending inventory management strategies.\n",
       "8. **Financial Analysis and Forecasting**: Generative AI can help businesses analyze financial data, identify trends, and predict future revenue streams. This can assist in making informed investment decisions and developing effective business strategies.\n",
       "9. **Human Resource Management**: Generative AI can be used to automate HR tasks, such as generating recruitment ads, screening resumes, and creating employee onboarding materials.\n",
       "10. **Digital Twin Development**: Generative AI can help businesses create digital twins of their physical assets, such as buildings or machines. This can assist in optimizing energy consumption, reducing maintenance costs, and improving overall efficiency.\n",
       "\n",
       "Some specific examples of businesses that are already leveraging generative AI include:\n",
       "\n",
       "* **Amazon**: Uses generative AI to optimize product recommendations, improve customer service chatbots, and automate marketing tasks.\n",
       "* **IBM**: Uses generative AI to develop personalized customer service solutions, create interactive content, and analyze large datasets for business insights.\n",
       "* **Dow Chemical**: Uses generative AI to design new materials and products, such as sustainable plastics and textiles.\n",
       "\n",
       "These are just a few examples of the many businesses that are already leveraging generative AI to drive innovation and growth."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "Markdown(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses automate content creation, reduce costs, and improve consistency.\n",
      "2. **Digital Product Creation**: Generative AI can be used to create customized digital products, such as e-books, videos, podcasts, and courses. This can help businesses offer unique and personalized experiences for their customers.\n",
      "3. **Product Design and Prototyping**: Generative AI can assist in designing and prototyping products, reducing the need for manual labor and improving product innovation speed.\n",
      "4. **Image and Video Generation**: Generative AI can create high-quality images and videos for marketing campaigns, website content, and social media platforms. This can help businesses improve their visual branding and storytelling.\n",
      "5. **Chatbots and Virtual Assistants**: Generative AI can be used to create sophisticated chatbots and virtual assistants that provide personalized customer support and improve user experience.\n",
      "6. **Text Summarization and Data Analysis**: Generative AI can summarize large datasets, identify key insights, and create actionable recommendations for businesses.\n",
      "7. **Automated Sales and Marketing Automation**: Generative AI can help automate sales and marketing processes, such as lead generation, email campaigns, and personalized messaging.\n",
      "8. **Customized Customer Experiences**: Generative AI can be used to create personalized product recommendations, offers, and content that cater to individual customer needs and preferences.\n",
      "9. **Predictive Maintenance and Fault Prediction**: Generative AI can analyze sensor data, predict equipment failures, and provide insights for maintenance scheduling, reducing downtime and increasing efficiency.\n",
      "10. **Creative Writing and Copywriting**: Generative AI can assist in creative writing and copywriting tasks, such as content optimization, keyword research, and SEO-friendly writing.\n",
      "\n",
      "Some industries that are particularly well-suited for generative AI applications include:\n",
      "\n",
      "1. Media and Entertainment: Creating customized content, audio-visuals, and interactive experiences.\n",
      "2. E-commerce: Personalized product recommendations, automated customer support, and optimized marketing campaigns.\n",
      "3. Healthcare: Predictive analytics, personalized patient care, and disease diagnosis.\n",
      "4. Finance: Risk analysis, portfolio optimization, and regulatory compliance.\n",
      "5. Education: Personalized learning content, adaptive assessments, and talent development.\n",
      "\n",
      "These are just a few examples of the business applications of generative AI. As the technology continues to evolve, we can expect even more innovative use cases across various industries and domains.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I'm trying to understand what LLMs are. Hmm, they're these big AI models that can answer questions and do text tasks really well. But how exactly do they work? Let me think about the parts mentioned—neural networks, attention, and transformers.\n",
       "\n",
       "Starting with neural networks... I know they have layers, like an input layer where you feed data in, hidden layers that process information, and an output layer to make decisions or predictions. Parameters are like the weights in those layers, right? So each parameter contributes to the model's ability to learn from data. But how complex is this all about?\n",
       "\n",
       "Then there's attention. I've heard it's a key component. Unlike some models where every word matters as much, attention focuses on which words are most relevant for understanding what the user said. Maybe like focusing the model more on when someone asks for advice and less on irrelevant questions.\n",
       "\n",
       "And then transformers. That sounds familiar. They have self-attention layers in each block. Self-attention means the model looks at its own outputs from previous steps to determine which parts of the input are most important. It's different from attention where different models use it differently—maybe more focused on internal dependencies within the same layer.\n",
       "\n",
       "Wait, so if I put this together, an LLM uses a neural network in each transformation block. Each block has these self-attention layers that help the model understand and process parts of the text more effectively by paying attention to relevant information. That must be how they focus on important parts of the input while giving some space to unimportant stuff.\n",
       "\n",
       "I'm still a bit confused about how all this translates to real models like GPT or BERT. Oh, right, both use these transformer-based neural networks. So each layer in the transformer is another neural network that processes attention across sequences and then outputs transformed information for the next layer until a final output step.\n",
       "\n",
       "So putting it together: The core concepts are using a neural network with self-attention layers within transformation blocks for processing text inputs. That makes sense because it allows models to focus on relevant contexts while maintaining some ability to consider all parts of the text, which is especially useful for answering questions like who did something or what advice someone gave.\n",
       "\n",
       "I think I get it now. The key ideas are that LLMs leverage a neural network with self-attention to process inputs, and their architecture (like transformers) adds layers where each can focus on relevant information while maintaining some general context.\n",
       "</think>\n",
       "\n",
       "LLMs, such as models developed by OpenAI through GPT or BERT, operate based on several core concepts. These include:\n",
       "\n",
       "1. **Neural Networks**: LLMs utilize a complex network of layers designed for pattern recognition and decision-making. This includes an input layer for data feeding in, hidden layers for processing information, and an output layer for making predictions.\n",
       "\n",
       "2. **Attention Mechanisms**: At the heart of these models is attention, which allows the model to focus on relevant parts of the input text. For example, when a user asks for advice or provides an explanation, the model pays more attention to the most pertinent aspects, enhancing accuracy and relevance.\n",
       "\n",
       "3. **Transformers (MLP-based Models)**: These models employ self-attention layers in each transformer block. Self-attention enables each layer to weigh its own outputs based on previous inputs and output transformed information for subsequent steps. This allows models to process input without external supervision, capturing both internal dependencies within a single layer.\n",
       "\n",
       "Together, neural networks with attention mechanisms and transformers enable LLMs to efficiently process text data by striking a balance between focusing on relevant contexts while maintaining general understanding, making them powerful tools for answering questions and handling complex tasks like text analysis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f389125a-d7ae-4ddb-95a4-f2366295049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e568bc-f9ae-4f24-b082-429eb24113a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f32071-5c4e-4a5b-85aa-c7665947aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = \"chevalblanc/gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebae81e8-9a87-469d-af99-07b232c55066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5ffcbd1-2d0a-4010-aab3-e1d02a6f1a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Citing a lack of evidence or an absence of criminal intent, prosecutors in the House Select Committee on January 6 declined to recommend civil legal action against Trump for his role in inciting last year's Capitol attacks.\r\n",
       "\"Due to our careful analysis we have determined that there are not grounds under this statute and within these circumstances where any charges related to statements made during the hearing could be brought,\" says a brief statement from prosecutors obtained by CNN. \"At no point did Chairman Bennie Thompson seek or agree on a recommendation of criminal action in relation to President Trump's testimonies.\"\r\n",
       "\r\n",
       "The House committee has been investigating what role former president Donald Trump played in fostering the Jan 6 insurrection, which led to six deaths and prompted Congress to implement new security measures at Capitol Hill. The FBI said that last year it received more than one million tips related to events surrounding the January attack on the US Capitol building.\r\n",
       "\r\n",
       "Chairman Bennie Thompson of Mississippi had previously told reporters a full report from his committee detailing what transpired during Trump's testimony will be released \"shortly\" with some details redacted, but no specific timeline was provided. The White House has thus far denied that any members have spoken to President Donald Trump since last January.\r\n",
       "\r\n",
       "Trump himself claims he is considering running for president again in 2024 amid speculation about a potential challenge against sitting Vice-President Kamala Harris. A spokesperson from the Biden administration said, however, that officials would be focused on ensuring public security during next year's election and had \"no reason to speculate beyond Election Day.\"\r\n",
       "\r\n",
       "The full report will presumably include Trump’s comments concerning his response following President Joe Biden winning last November 3rd elections against Trump in an apparent landslide victory. In a separate development this week news surfaced about the resignation of FBI director Chris Wray, who stepped down from that role after nine years on Tuesday (21 April) afternoon amid concerns over the bureau's political bias.\r\n",
       "\r\n",
       "Trump tweeted in response to reports earlier Wednesday morning indicating his comments related specifically toward claims he was acting out on instructions or orders given by then-chairman Tho..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.cnn.com/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
